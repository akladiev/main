name: Gathering Pipeline Statistics
on:
  workflow_dispatch:
  pull_request:
  push:
    branches:
      - main

jobs:
  Gather_Statistics:
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        pipelineToCollect: ['linux.yml']
        # pipelineToCollect: ['linux.yml', 'android_arm64.yml', 'fedora.yml', 'linux_conditional_compilation.yml', 'linux_riscv.yml', 'webassembly.yml']
    defaults:
      run:
        shell: bash
    runs-on: ubuntu-latest
    env:
      ARTIFACTS_DIR: ${{ github.workspace }}/artifacts
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Create Artifacts Directory
        run: mkdir -p ${{ env.ARTIFACTS_DIR }}

      - name: Show Context
        uses: actions/github-script@v6
        with:
          script: |
            console.log(context)
            console.log(context.runId)
            console.log(context.payload.repository.full_name)

      - uses: actions/setup-node@v3
        with:
          node-version: 16

      - run: npm install xlsx

      - name: Gather Workflows Data
        uses: actions/github-script@v6
        with:
          github-token: ${{ secrets.MY_PAT }}
          script: |
            const fs = require('fs');
            const XLSX = require('xlsx');
            
            // TODO: use context.payload.repository.organization
            const org = 'openvinotoolkit'
            
            // TODO: use context.payload.repository.name
            const repositoryName = 'openvino'
            
            function sleep(ms) {
                return new Promise(resolve => setTimeout(resolve, ms));
            }
            
            async function getLabelsForPR(prNumber) {
              const labels = []
              const prInfo = await github.rest.pulls.get({
                'owner': org,
                'repo': repositoryName,
                'pull_number': prNumber,
              });
              
              for (const labelInfo of prInfo.labels) {
                labels.push(labelInfo.name)
              }
              return labels.toString()
            }
            
            const date = new Date();
            
            let day = date.getDate();
            // Month is starting from 0 for some reason
            let month = date.getMonth() + 1;
            const year = date.getFullYear();
            
            if (day < 10) {
              day = `0${day}`
            }
            
            if (month < 10) {
              month = `0${month}`
            }
            
            // Only gather workflow runs that ran on the specified date or after
            // const dateToStartGatheringFrom = `>=${year}-${month}-${day}`
            
            // TODO: use dynamic date
            const dateToStartGatheringFrom = `>=2023-07-05`
            console.log(`dateToStartGatheringFrom: ${dateToStartGatheringFrom}`)
            
            const pipelineName = `${{ matrix.pipelineToCollect }}`
            
            // Check how many pipelines were executed
            const workflowRunsData = await github.rest.actions.listWorkflowRuns({
              'owner': org,
              'repo': repositoryName,
              'workflow_id': pipelineName,
              'status': 'completed',
              'created': dateToStartGatheringFrom,
              'per_page': 1
            })
            
            const perPageCount = 50
            let pagesToCollect = Math.ceil(workflowRunsData.data.total_count / perPageCount)
            console.log(`TOTAL # OF COMPLETED RUNS: ${workflowRunsData.data.total_count}`)
            console.log(`PAGES TO COLLECT: ${pagesToCollect}`)
            
            const workflowRuns = []
            const workflowRunsStats = []
            
            pagesToCollect = pagesToCollect > 10 ? 10 : pagesToCollect;

            for (let pageNumber = 1; pageNumber <= pagesToCollect; pageNumber++) {
            
                console.log(`Collecting page #${pageNumber}.`)

                let workflowRunsDataPerPage = await github.rest.actions.listWorkflowRuns({
                    'owner': org,
                    'repo': repositoryName,
                    'workflow_id': pipelineName,
                    'status': 'success',
                    'created': dateToStartGatheringFrom,
                    'per_page': perPageCount,
                    'page': pageNumber
                })
            
                console.log(`workflowsPerPageCount: ${workflowRunsDataPerPage.data.workflow_runs.length}`)

                workflowRuns.push(...workflowRunsDataPerPage.data.workflow_runs)
                console.log(`workflowRuns LENGTH AFTER PAGE COLLECTION: ${workflowRuns.length}`)
                
                console.log(`Sleeping for 3 seconds.`)
                await sleep(3 * 1000);
            }
            
            console.log('Aggregating data for XLSX')

            for (const workflowData of workflowRuns) {

                const workflowRunStats = {}

                const runID = workflowData.id

                workflowRunStats['Run ID'] = runID
                workflowRunStats['URL'] = workflowData.html_url
                workflowRunStats['Author'] = workflowData.head_commit.author.name
                workflowRunStats['Source Branch'] = workflowData.head_branch
                if (workflowData.head_branch === 'master') {
                  continue;
                }
                workflowRunStats['Started At'] = workflowData.run_started_at ? workflowData.run_started_at : undefined
                workflowRunStats['Commit Time'] = workflowData.head_commit && workflowData.head_commit.timestamp ? workflowData.head_commit.timestamp : 'No data'
                workflowRunStats['Status'] = workflowData.conclusion
                workflowRunStats['Jobs'] = []
                console.log(JSON.stringify(workflowData.pull_requests))
                console.log(JSON.stringify(workflowData.pull_requests))
                console.log(JSON.stringify(workflowData.pull_requests))
        
                workflowRunStats['Pull Request URL'] = workflowData.pull_requests.length ? workflowData.pull_requests[0].url : 'EMPTY'
                
                workflowRunStats['Labels'] = 'EMPTY'
                
                const pullRequestNumber = workflowData.pull_requests.length ? workflowData.pull_requests[0].number : undefined
                if (pullRequestNumber) {
                  workflowRunStats['Labels'] = await getLabelsForPR(pullRequestNumber)
                }
            
                let pipelineEndDate;
                let workflowDuration = 0
                let workflowDurationFromStartToFinish = 0

                const workflowJobs = await github.rest.actions.listJobsForWorkflowRunAttempt({
                    'owner': org,
                    'repo': repositoryName,
                    'run_id': runID,
                // By default only latest attempt is returned, and if only one of workflowJobs was rebuilt,
                // created_at value is updated for all jobs in workflow, including non-rebuilt ones
                // causing created_at being older than started_at for non-rebuilt jobs
                // This breaks our waiting time statistics, so for now let's check only data for the 1st attempt
                // (it seems that we can't count and retrieve all attempts at once anyways)
                    'attempt_number': 1
                })
            
                let longestJob = {
                  duration: 0,
                  completed_at: undefined
                }
                
                for (const workflowJob of workflowJobs.data.jobs) {
                    const jobCreate = new Date(workflowJob.created_at)
                    const jobStart = new Date(workflowJob.started_at)
                    const jobEnd = new Date(workflowJob.completed_at)
                    const waitDuration = Math.abs(jobStart - jobCreate) / 1000 / 60
                    const jobDuration = Math.abs(jobEnd - jobStart) / 1000 / 60
                    const runner = workflowJob.labels ? workflowJob.labels[0] : 'No data'

                    workflowRunStats['Jobs'].push({
                        Job: workflowJob.name,
                        Created: jobCreate,
                        Started: jobStart,
                        Finished: jobEnd,
                        Duration: jobDuration,
                        Runner: runner
                        WaitDuration: waitDuration,
                        Status: workflowJob.conclusion
                    })
                    
                    // The longest job out of those running in parallel
                    // use its completed_at time to determine when the pipeline ended
                    if (jobDuration > longestJob['duration']) {
                      longestJob = {
                        duration: jobDuration,
                        completed_at: workflowJob.completed_at
                      }
                    }
            
                    workflowDuration += jobDuration
                }
            
                pipelineEndDate = longestJob['completed_at']

                if (workflowData.run_started_at && pipelineEndDate) {
                    const start = new Date(workflowData.run_started_at)
                    const end = new Date(pipelineEndDate)
                    workflowDurationFromStartToFinish = Math.abs(end - start) / 1000 / 60
                }
                workflowRunStats['Total Duration'] = workflowDuration
                workflowRunStats['Duration from Start to Finish'] = workflowDurationFromStartToFinish
            
                workflowRunsStats.push(workflowRunStats)
            }

            console.log(`TOTAL LENGTH OF workflowRunsStats: ${workflowRunsStats.length}`)

            let rows = [];
            workflowRunsStats.forEach(function (entry, index) {
                const row = {
                    'Run ID': entry['Run ID'],
                    'URL': entry.URL,
                    'Author': entry.Author,
                    'Commit Time': entry['Commit Time'],
                    'Source Branch': entry['Source Branch'],
                    'Pull Request URL': entry['Pull Request URL'],
                    'Pipeline Started At': entry['Started At'],
                    'Status': entry.Status,
                    'Labels': entry.Labels,
                    'Total Pipeline Duration (Mins)': entry['Total Duration'],
                    'Duration from Start to Finish (Mins)': entry['Duration from Start to Finish']
                };
                entry.Jobs.forEach(function (job) {
                    row[job.Job + '_Job_Status'] = job.Status;
                    row[job.Job + '_Job_Created'] = job.Created;
                    row[job.Job + '_Job_Started'] = job.Started;
                    row[job.Job + '_Job_Finished'] = job.Finished;
                    row[job.Job + '_Job_Duration (Mins)'] = job.Duration;
                    row[job.Job + '_Job_Runner'] = job.Runner;
                    row[job.Job + '_Job_Wait_Duration (Mins)'] = job.WaitDuration;
                });
                rows.push(row);
                if (!(index % 100)) {
                  console.log(`Done with ${index} rows...`)
                }
            });

            console.log(`TOTAL # OF ROWS TO WRITE: ${rows.length}`)

            const worksheet = XLSX.utils.json_to_sheet(rows);
            const workbook = XLSX.utils.book_new();
            XLSX.utils.book_append_sheet(workbook, worksheet, 'Workflow Runs');
            const artifactPath = `${{ env.ARTIFACTS_DIR }}/workflowRuns_${pipelineName}.xlsx`

            XLSX.writeFile(workbook, artifactPath);

      - name: Upload gathered data
        uses: actions/upload-artifact@v3
        with:
          name: Workflow Runs Statistics
          path: ${{ env.ARTIFACTS_DIR }}/workflowRuns*.xlsx
          if-no-files-found: 'error'
